{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu3HV4nnVeKY4/3Sm0SeaD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbberylll/Summer_Project_ESAA_YB_2/blob/main/%EB%B0%A9%ED%95%99%EC%8A%A4%ED%84%B0%EB%94%94_%EC%88%98%EC%83%81%EC%9E%91_%EB%A6%AC%EB%B7%B0_1%EC%B0%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asndy-QiCkxH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/datasets/shwetabh123/mall-customers?utm_source=chatgpt.com"
      ],
      "metadata": {
        "id": "8xDDy42qVEoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mall Customer Segmentation (Clustering) — Replication & Study\n",
        "\n",
        "## 1) 사용한 데이터와 주제 설명\n",
        "- **데이터**: Kaggle “Mall Customers” (행: 고객, 열: Gender, Age, Annual Income (k$), Spending Score (1-100), CustomerID)\n",
        "- **주제**: 고객의 구매/지출 특성을 비지도 학습으로 **군집화**하여, 마케팅 타기팅/세그먼트 인사이트를 도출\n",
        "\n",
        "## 2) 어떤 기법이 적용됐는지\n",
        "- **전처리**: 결측/중복 점검, 이상치 탐색, 범주형(성별) 인코딩, 수치형 스케일링(StandardScaler)\n",
        "- **차원축소/시각화**: PCA(2D), t-SNE(옵션)\n",
        "- **클러스터링**: K-Means(기본), Gaussian Mixture Model(GMM), Agglomerative(ward)\n",
        "- **모델 선정**: Elbow(Within-Cluster-Sum-of-Squares), Silhouette Score, Calinski–Harabasz, Davies–Bouldin, (GMM은 BIC 추가)\n",
        "\n",
        "## 3) 어떻게 문제에 접근했는지\n",
        "1. **EDA**로 변수 분포/상관관계/스케일 이슈 파악  \n",
        "2. **전처리**에서 성별 인코딩, 수치 표준화 수행  \n",
        "3. **모델 선택**을 위해 K=2~10 범위에서 Elbow/Silhouette/CH/DB 지표로 후보 비교  \n",
        "4. **모델링**: K-Means 기본, GMM/Agglomerative로 대안 비교  \n",
        "5. **결과 해석**: PCA 2D 투영을 통한 시각화 + 군집별 프로파일링(평균/분포/성별비, 나이 구간)\n",
        "\n",
        "## 4) 분석 과정 코드 흐름 (EDA → 전처리 → 모델링)\n",
        "- **EDA**: 결측/중복 확인 → 분포/Scatter → 상관계수\n",
        "- **전처리**: 범주형 원-핫, 수치 스케일링, 피처 셋 구성\n",
        "- **모델링**:\n",
        "  - 후보 K 전역 탐색(Elbow+Silhouette 등)\n",
        "  - KMeans / GMM / Agglomerative 적합 및 평가지표 비교\n",
        "  - 최종 모델 선택 및 시각화(PCA, t-SNE 옵션)\n",
        "- **해석/리포팅**: 클러스터별 통계 요약, 표/그림 저장\n",
        "\n",
        "## 5) 차별점 및 배울 점\n",
        "- 단순 K-Means 결과에 그치지 않고 **여러 평가지표**로 최적 K와 모델을 검증\n",
        "- **GMM(BIC)**와 **Agglomerative**까지 비교하여 데이터 분포/구조적 특징을 다각도로 확인\n",
        "- **클러스터 프로파일링**(성별/나이 구간/소득/지출)으로 **의사결정에 유용한 인사이트** 도출\n",
        "- 클러스터링의 핵심: “**평가 지표 + 프로파일링**” 없이는 실용적 결론이 어렵다는 점을 체감"
      ],
      "metadata": {
        "id": "zFmNSqMgClTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. K-Means (기본)\n",
        "\n",
        "아이디어: 데이터 포인트를 K개의 클러스터 중심(centroid)에 할당하고, 각 클러스터의 평균을 기준으로 반복 갱신\n",
        "\n",
        "클러스터 모양 가정: 구형(원형)이고 크기가 비슷하며 밀집도가 유사해야 잘 작동\n",
        "\n",
        "장점\n",
        "*   계산이 빠르고 대규모 데이터셋에 잘 맞음\n",
        "*   구현이 단순하고 직관적\n",
        "\n",
        "단점\n",
        "*   구형 클러스터만 잘 나눔 → 타원형/불규칙한 모양은 잘 안됨\n",
        "*   K(군집 수)를 사전에 지정해야 함\n",
        "*   이상치(outlier)에 민감\n",
        "\n",
        "---\n",
        "## 2. Gaussian Mixture Model (GMM)\n",
        "\n",
        "아이디어: 데이터를 여러 개의 정규분포(가우시안 분포)의 혼합으로 가정 → 각 점은 “클러스터에 속할 확률”을 가짐 (soft clustering)\n",
        "\n",
        "클러스터 모양 가정: 타원형 가능 (분포의 공분산 행렬을 활용)\n",
        "\n",
        "장점\n",
        "*   K-Means보다 유연 → 타원형, 경계가 불분명한 클러스터도 모델링 가능\n",
        "*   각 데이터가 여러 클러스터에 속할 확률을 제공 → 해석력이 더 풍부\n",
        "\n",
        "단점\n",
        "*   계산이 K-Means보다 무겁고 느림\n",
        "*   클러스터 수 K도 지정해야 함\n",
        "*   데이터가 정규분포 가정을 크게 벗어나면 성능이 떨어질 수 있음\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 3.Agglomerative Clustering (Ward)\n",
        "\n",
        "아이디어: bottom-up 방식의 계층적(hierarchical) 클러스터링 → 각 점에서 시작해 가까운 두 클러스터를 순차적으로 합쳐감\n",
        "\n",
        "Ward linkage: 클러스터 합칠 때 **제곱 오차합 증가량(variance 증가)**을 최소화하는 방식\n",
        "\n",
        "클러스터 모양 가정: 비교적 유연, 데이터 분포에 따라 다양한 구조 가능\n",
        "\n",
        "장점\n",
        "*   계층적 구조(dendrogram)를 제공 → 클러스터 간 관계를 시각적으로 해석 가능\n",
        "*   K를 지정하지 않고 dendrogram 잘라서 선택할 수도 있음\n",
        "\n",
        "\n",
        "단점\n",
        "*   계산량이 많음 (특히 큰 데이터셋에서)\n",
        "*   클러스터 수 선택이 주관적일 수 있음\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "K-Means: 빠르고 단순, “구형 클러스터”에 적합\n",
        "\n",
        "GMM: 확률 기반, “타원형/유연한 클러스터” 가능\n",
        "\n",
        "Agglomerative (Ward): 계층적 구조를 보여줌, 해석력 ↑, 대규모 데이터에선 다소 무거움\n"
      ],
      "metadata": {
        "id": "wRgY7npHC_ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_f4JLurEQMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "클러스터링은 'label'이 없기 때문에 몇 개의 클러스터를 잡을지와 성능을 평가할 때 내부 지표를 사용함\n",
        "\n",
        "1. Elbow Method (Within-Cluster-Sum-of-Squares, WCSS)\n",
        "정의: 각 클러스터 안에서 중심점(centroid)까지 거리 제곱합을 모두 더한 값\n",
        "아이디어: K가 커질수록 WCSS는 감소하지만, 어느 순간부터는 개선폭이 줄어듦 → “팔꿈치(elbow)”처럼 꺾이는 지점이 최적 K로 간주\n",
        "\n",
        " *   장점: 직관적, 시각화로 이해하기 쉬움\n",
        " *   단점: 꺾이는 지점이 애매한 경우도 많음\n",
        "\n",
        "2. Silhouette Score\n",
        "정의: 한 점의 “응집도(cohesion)”와 “분리도(separation)”를 동시에 고려\n",
        "   *   s(i) = (b(i) - a(i)) / max(a(i), b(i))\n",
        "   *   a(i): 같은 클러스터 내 평균 거리 (작을수록 좋음)\n",
        "   *   b(i): 가장 가까운 다른 클러스터와의 평균 거리 (클수록 좋음)\n",
        "\n",
        " *   장점: 직관적으로 해석 가능, 클러스터 수 결정에 자주 사용\n",
        " *   단점: 고차원 데이터에서는 과도하게 단순화될 수 있음\n",
        "\n",
        "\n",
        "3. Calinski–Harabasz Index (CH Index, Variance Ratio Criterion)\n",
        "\n",
        "정의: 클러스터 간 분산(between-cluster variance) / 클러스터 내 분산(within-cluster variance)\n",
        "variance)\n",
        "\n",
        "공식:\n",
        "\n",
        "𝐶𝐻 = (𝑇𝑟(𝐵𝑘)/(𝑘−1))/(𝑇𝑟(𝑊𝑘)/(𝑛−𝑘))\n",
        "\n",
        "    1.   B_k: 클러스터 간 분산행렬\n",
        "    2.   W_k: 클러스터 내 분산행렬\n",
        "\n",
        "\n",
        "해석: 값이 클수록 클러스터 간은 멀리 떨어지고 내부는 응집 → 좋은 클러스터링\n",
        " *   장점: 계산이 빠르고 직관적\n",
        " *   단점: 클러스터 수가 많을 때 과대평가할 가능성\n",
        "\n",
        "\n",
        "4. Davies–Bouldin Index (DB Index)\n",
        "\n",
        "정의: 각 클러스터가 얼마나 “다른 클러스터와 비슷한지” 측정\n",
        "클러스터 간 거리 대비, 각 클러스터 내부의 흩어짐(분산)을 비율로 계산\n",
        "\n",
        "범위: 0 이상 (낮을수록 좋음)\n",
        "장점: 클러스터 간 분리와 응집도를 동시에 반영\n",
        "단점: 일부 데이터 분포에서 극단값에 민감\n",
        "\n",
        "\n",
        "5. Bayesian Information Criterion (BIC, GMM 전용)\n",
        "\n",
        "정의: 모델의 적합도(likelihood)와 복잡도(파라미터 수)를 동시에 고려하는 정보 기준\n",
        "\n",
        "𝐵𝐼𝐶 = −2ln⁡(𝐿)+𝑝ln⁡(𝑛)\n",
        "\n",
        "L: 최대우도값 (likelihood)\n",
        "p: 추정 파라미터 수\n",
        "n: 데이터 개수\n",
        "\n",
        "해석: 값이 낮을수록 좋은 모델 (적합도 높음, 복잡도 낮음)\n",
        "장점: GMM 같은 확률모형 기반 클러스터링에 적합\n",
        "단점: 반드시 확률적 모델이어야 적용 가능 (K-Means에는 못 씀)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jZwSds8WEA3E"
      }
    }
  ]
}